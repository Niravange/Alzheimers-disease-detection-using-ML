{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images :  6400\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "image_data_folder_path = \"C:/Users/surya/OneDrive/Desktop/Alzheimers/Alzheimer_s Dataset\"\n",
    "imagePaths = sorted(list(paths.list_images(image_data_folder_path)))\n",
    "total_number_of_images = len(imagePaths)\n",
    "print(\"Total number of images : \",total_number_of_images)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (208, 176)\n"
     ]
    }
   ],
   "source": [
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE)\n",
    "    image1 = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "    data.append(image1)\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "print (\"data\",data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "#data = np.array(data, dtype=\"float\") / 255.0\n",
    "data = np.array(data, dtype=\"float\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5120, 208, 176)\n",
      "X_test shape: (1280, 208, 176)\n"
     ]
    }
   ],
   "source": [
    "(X_train,X_test,y_train,y_test) = train_test_split(data,labels, test_size=0.2, stratify = labels,shuffle = True, random_state=100)\n",
    "print (\"X_train shape:\",X_train.shape)\n",
    "print (\"X_test shape:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test= lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length X_train: 5120\n",
      "length X_test: 1280\n",
      "length y_train: 5120\n",
      "length y_test: 1280\n"
     ]
    }
   ],
   "source": [
    "print('length X_train:', len(X_train))\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_train:', len(y_train))\n",
    "print('length y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(5120,208,176,1)\n",
    "X_test = np.array(X_test).reshape(1280,208,176,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 208\n",
    "width = 176\n",
    "depth=1\n",
    "\n",
    "inputShape = (height, width,depth)\n",
    "\n",
    "classes = len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MildDemented', 'ModerateDemented', 'NonDemented',\n",
       "       'VeryMildDemented'], dtype='<U16')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.7852161785216178, 1: 25.098039215686274, 2: 0.5, 3: 0.7142857142857143}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1 2 3], y=[3 2 2 ... 2 2 2] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "y_integers = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "class_weights1 = dict(enumerate(class_weights))\n",
    "print(class_weights1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 206, 174, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 206, 174, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 103, 87, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 103, 87, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 101, 85, 64)       18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 101, 85, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 40, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 61440)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               31457792  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 31,555,460\n",
      "Trainable params: 31,553,988\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(208,176,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "EPOCHS = 100\n",
    "BS = 32\n",
    "NUM_CLASSES = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\"AD_Stages_model.h5\", save_best_only=True)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.001)\n",
    "\n",
    "callbacks=[checkpoint_cb, learning_rate_reduction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "160/160 [==============================] - 377s 2s/step - loss: 1.5126 - accuracy: 0.4159 - val_loss: 82.4167 - val_accuracy: 0.1398\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 405s 3s/step - loss: 0.7015 - accuracy: 0.6112 - val_loss: 31.8369 - val_accuracy: 0.1523\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 373s 2s/step - loss: 0.4988 - accuracy: 0.7167 - val_loss: 220.8446 - val_accuracy: 0.0102\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 353s 2s/step - loss: 0.3517 - accuracy: 0.7932 - val_loss: 15.3746 - val_accuracy: 0.0836\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.2420 - accuracy: 0.8687 - val_loss: 1.1122 - val_accuracy: 0.6023\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.1977 - accuracy: 0.8931 - val_loss: 0.3402 - val_accuracy: 0.8711\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.1662 - accuracy: 0.9034 - val_loss: 0.9640 - val_accuracy: 0.6422\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 346s 2s/step - loss: 0.1157 - accuracy: 0.9372 - val_loss: 0.4961 - val_accuracy: 0.7969\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 350s 2s/step - loss: 0.0886 - accuracy: 0.9524 - val_loss: 1.7790 - val_accuracy: 0.5281\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0784 - accuracy: 0.9606 - val_loss: 1.4984 - val_accuracy: 0.5906\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0782 - accuracy: 0.9547 - val_loss: 0.3620 - val_accuracy: 0.8641\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0688 - accuracy: 0.9623 - val_loss: 0.1448 - val_accuracy: 0.9406\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0531 - accuracy: 0.9718 - val_loss: 0.1333 - val_accuracy: 0.9523\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0430 - accuracy: 0.9783 - val_loss: 0.1507 - val_accuracy: 0.9398\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0450 - accuracy: 0.9746 - val_loss: 0.2785 - val_accuracy: 0.8953\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 346s 2s/step - loss: 0.0713 - accuracy: 0.9622 - val_loss: 0.0969 - val_accuracy: 0.9648\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0457 - accuracy: 0.9760 - val_loss: 0.0446 - val_accuracy: 0.9867\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0432 - accuracy: 0.9763 - val_loss: 0.0696 - val_accuracy: 0.9750\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0514 - accuracy: 0.9660 - val_loss: 0.0453 - val_accuracy: 0.9805\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 351s 2s/step - loss: 0.0475 - accuracy: 0.9733 - val_loss: 0.1576 - val_accuracy: 0.9492\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0417 - accuracy: 0.9784 - val_loss: 0.0519 - val_accuracy: 0.9844\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 349s 2s/step - loss: 0.0352 - accuracy: 0.9805 - val_loss: 2.4715 - val_accuracy: 0.5109\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0421 - accuracy: 0.9830 - val_loss: 0.2087 - val_accuracy: 0.9297\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 349s 2s/step - loss: 0.0431 - accuracy: 0.9772 - val_loss: 0.2107 - val_accuracy: 0.9219\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0327 - accuracy: 0.9842 - val_loss: 0.2203 - val_accuracy: 0.9219\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 349s 2s/step - loss: 0.0316 - accuracy: 0.9841 - val_loss: 0.0665 - val_accuracy: 0.9750\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0372 - accuracy: 0.9818 - val_loss: 0.0367 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0330 - accuracy: 0.9822 - val_loss: 0.3283 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0345 - accuracy: 0.9835 - val_loss: 0.8162 - val_accuracy: 0.8156\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0293 - accuracy: 0.9848 - val_loss: 0.1247 - val_accuracy: 0.9594\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0307 - accuracy: 0.9801 - val_loss: 0.0645 - val_accuracy: 0.9781\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 349s 2s/step - loss: 0.0266 - accuracy: 0.9851 - val_loss: 0.0885 - val_accuracy: 0.9719\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0260 - accuracy: 0.9853 - val_loss: 0.8180 - val_accuracy: 0.7563\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 346s 2s/step - loss: 0.0351 - accuracy: 0.9845 - val_loss: 0.0541 - val_accuracy: 0.9820\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0248 - accuracy: 0.9870 - val_loss: 0.0659 - val_accuracy: 0.9750\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0312 - accuracy: 0.9844 - val_loss: 0.1626 - val_accuracy: 0.9469\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 347s 2s/step - loss: 0.0402 - accuracy: 0.9794 - val_loss: 0.0969 - val_accuracy: 0.9680\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 346s 2s/step - loss: 0.0382 - accuracy: 0.9817 - val_loss: 0.0738 - val_accuracy: 0.9734\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0259 - accuracy: 0.9884 - val_loss: 0.0877 - val_accuracy: 0.9742\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 344s 2s/step - loss: 0.0280 - accuracy: 0.9822 - val_loss: 0.0404 - val_accuracy: 0.9883\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 346s 2s/step - loss: 0.0241 - accuracy: 0.9855 - val_loss: 0.0723 - val_accuracy: 0.9797\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 346s 2s/step - loss: 0.0314 - accuracy: 0.9863 - val_loss: 0.1204 - val_accuracy: 0.9539\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0400 - accuracy: 0.9807 - val_loss: 0.1256 - val_accuracy: 0.9602\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0274 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0226 - accuracy: 0.9899 - val_loss: 0.0304 - val_accuracy: 0.9891\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0141 - accuracy: 0.9937 - val_loss: 0.0752 - val_accuracy: 0.9766\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0127 - accuracy: 0.9940 - val_loss: 0.0449 - val_accuracy: 0.9852\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0159 - accuracy: 0.9920 - val_loss: 0.6098 - val_accuracy: 0.9008\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0166 - accuracy: 0.9915 - val_loss: 0.2634 - val_accuracy: 0.9297\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 348s 2s/step - loss: 0.0189 - accuracy: 0.9914 - val_loss: 0.0504 - val_accuracy: 0.9836\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 343s 2s/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.0939 - val_accuracy: 0.9734\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0318 - accuracy: 0.9832 - val_loss: 0.0349 - val_accuracy: 0.9875\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 343s 2s/step - loss: 0.0161 - accuracy: 0.9919 - val_loss: 0.0519 - val_accuracy: 0.9852\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0181 - accuracy: 0.9908 - val_loss: 0.0338 - val_accuracy: 0.9891\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0138 - accuracy: 0.9928 - val_loss: 0.3409 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0156 - accuracy: 0.9923 - val_loss: 0.1995 - val_accuracy: 0.9422\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 345s 2s/step - loss: 0.0218 - accuracy: 0.9882 - val_loss: 0.0398 - val_accuracy: 0.9883\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0177 - accuracy: 0.9893 - val_loss: 0.0312 - val_accuracy: 0.9906\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0112 - accuracy: 0.9956 - val_loss: 0.0385 - val_accuracy: 0.9883\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0095 - accuracy: 0.9939 - val_loss: 0.0383 - val_accuracy: 0.9867\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0412 - accuracy: 0.9843 - val_loss: 0.4055 - val_accuracy: 0.8867\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0199 - accuracy: 0.9882 - val_loss: 2.1979 - val_accuracy: 0.7703\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0271 - accuracy: 0.9869 - val_loss: 1.1677 - val_accuracy: 0.6891\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 350s 2s/step - loss: 0.0379 - accuracy: 0.9822 - val_loss: 0.7123 - val_accuracy: 0.7797\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 353s 2s/step - loss: 0.0235 - accuracy: 0.9910 - val_loss: 0.0439 - val_accuracy: 0.9875\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0225 - accuracy: 0.9911 - val_loss: 0.0371 - val_accuracy: 0.9867\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0136 - accuracy: 0.9928 - val_loss: 0.0501 - val_accuracy: 0.9875\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.1082 - val_accuracy: 0.9602\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 340s 2s/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.0678 - val_accuracy: 0.9859\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0558 - val_accuracy: 0.9875\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0146 - accuracy: 0.9936 - val_loss: 0.0536 - val_accuracy: 0.9852\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0124 - accuracy: 0.9930 - val_loss: 0.5287 - val_accuracy: 0.8953\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0132 - accuracy: 0.9930 - val_loss: 0.2955 - val_accuracy: 0.9711\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.0983 - val_accuracy: 0.9789\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0186 - accuracy: 0.9912 - val_loss: 0.0828 - val_accuracy: 0.9797\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 342s 2s/step - loss: 0.0106 - accuracy: 0.9941 - val_loss: 0.0344 - val_accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0153 - accuracy: 0.9934 - val_loss: 0.3373 - val_accuracy: 0.9844\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 340s 2s/step - loss: 0.0112 - accuracy: 0.9932 - val_loss: 0.0374 - val_accuracy: 0.9914\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0115 - accuracy: 0.9936 - val_loss: 0.0646 - val_accuracy: 0.9836\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 341s 2s/step - loss: 0.0121 - accuracy: 0.9950 - val_loss: 0.0417 - val_accuracy: 0.9875\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 334s 2s/step - loss: 0.0074 - accuracy: 0.9952 - val_loss: 0.1906 - val_accuracy: 0.9430\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 330s 2s/step - loss: 0.0122 - accuracy: 0.9934 - val_loss: 0.1301 - val_accuracy: 0.9602\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 330s 2s/step - loss: 0.0161 - accuracy: 0.9934 - val_loss: 0.6892 - val_accuracy: 0.9453\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 329s 2s/step - loss: 0.0166 - accuracy: 0.9921 - val_loss: 0.0824 - val_accuracy: 0.9820\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 331s 2s/step - loss: 0.0217 - accuracy: 0.9902 - val_loss: 0.0825 - val_accuracy: 0.9828\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 329s 2s/step - loss: 0.0107 - accuracy: 0.9949 - val_loss: 0.4297 - val_accuracy: 0.9187\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 331s 2s/step - loss: 0.0243 - accuracy: 0.9889 - val_loss: 0.0686 - val_accuracy: 0.9828\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 330s 2s/step - loss: 0.0143 - accuracy: 0.9920 - val_loss: 0.2362 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 330s 2s/step - loss: 0.0289 - accuracy: 0.9866 - val_loss: 0.0411 - val_accuracy: 0.9883\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 384s 2s/step - loss: 0.0175 - accuracy: 0.9895 - val_loss: 0.0302 - val_accuracy: 0.9906\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 400s 3s/step - loss: 0.0116 - accuracy: 0.9926 - val_loss: 0.0313 - val_accuracy: 0.9914\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 399s 2s/step - loss: 0.0079 - accuracy: 0.9952 - val_loss: 0.0354 - val_accuracy: 0.9906\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 401s 3s/step - loss: 0.0080 - accuracy: 0.9961 - val_loss: 0.0234 - val_accuracy: 0.9898\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 401s 3s/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 0.3842 - val_accuracy: 0.9734\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 401s 3s/step - loss: 0.0158 - accuracy: 0.9924 - val_loss: 0.0631 - val_accuracy: 0.9883\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 401s 3s/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 1.3722 - val_accuracy: 0.9219\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 400s 2s/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.2850 - val_accuracy: 0.9492\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 400s 3s/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.0769 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 400s 3s/step - loss: 0.0122 - accuracy: 0.9929 - val_loss: 0.0793 - val_accuracy: 0.9852\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 400s 3s/step - loss: 0.0082 - accuracy: 0.9953 - val_loss: 0.0728 - val_accuracy: 0.9836\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, batch_size=BS,validation_data=(X_test,y_test), steps_per_epoch=len(X_train) // BS,epochs=EPOCHS, \n",
    "                        class_weight = class_weights1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_filter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    MildDemented       0.99      0.98      0.99       179\n",
      "ModerateDemented       1.00      1.00      1.00        13\n",
      "     NonDemented       0.97      1.00      0.98       640\n",
      "VeryMildDemented       1.00      0.96      0.98       448\n",
      "\n",
      "        accuracy                           0.98      1280\n",
      "       macro avg       0.99      0.98      0.99      1280\n",
      "    weighted avg       0.98      0.98      0.98      1280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(X_test, batch_size=10)\n",
    "print(classification_report(y_test.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[175,   0,   4,   0],\n",
       "       [  0,  13,   0,   0],\n",
       "       [  0,   0, 640,   0],\n",
       "       [  1,   0,  16, 431]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "pred_ls1 = np.argmax(predictions,axis=1)\n",
    "test_ls1 = np.argmax(y_test,axis=1)\n",
    "conf_arr1 = confusion_matrix(test_ls1, pred_ls1)\n",
    "conf_arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "conf_arr1 = confusion_matrix(test_ls1, pred_ls1)\n",
    "sns.heatmap(conf_arr1, cmap='Blues', annot=True) \n",
    "plt.imshow(conf_arr1, cmap=plt.cm.Blues)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title('Confusion matrix ')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = np.arange(1,len(history.history.get('loss'))+1)\n",
    "plt.plot(epoches, history.history.get('loss'), 'b',label='Loss')\n",
    "plt.plot(epoches, history.history.get('val_loss'),'k', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoches, history.history.get('accuracy'), 'b',label='Accuracy')\n",
    "plt.plot(epoches, history.history.get('val_accuracy'),'k', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
